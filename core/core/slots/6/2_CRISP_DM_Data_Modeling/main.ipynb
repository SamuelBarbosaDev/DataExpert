{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import (\n",
    "    datasets\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV\n",
    ")\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error\n",
    ")\n",
    "from sklearn.svm import (\n",
    "    SVR\n",
    ")\n",
    "from xgboost import (\n",
    "    XGBRegressor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guerrlr0/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "class DataModeling():\n",
    "    def __init__(self) -> None:\n",
    "        self.sobre_o_df = datasets.load_boston()\n",
    "        self.df = pd.DataFrame(\n",
    "            data=self.sobre_o_df.data,\n",
    "            columns=self.sobre_o_df.feature_names\n",
    "        )\n",
    "\n",
    "    def dataframe(self):\n",
    "        df = self.df.head(5)\n",
    "        display(df)\n",
    "\n",
    "    def chaves_do_df(self):\n",
    "        df = self.sobre_o_df.keys()\n",
    "        print(df)\n",
    "\n",
    "    def descrição_do_df(self):\n",
    "        df = self.sobre_o_df.DESCR\n",
    "        print(df)\n",
    "\n",
    "    def variavel_targat(self):\n",
    "        df = self.sobre_o_df.target\n",
    "        print(df)\n",
    "\n",
    "    def separação_de_train_e_test(self):\n",
    "        \"\"\"\n",
    "            Separação de Train/Test dataset padrão com \n",
    "            20% de massa para teste via metodo SKLEARN\n",
    "        \"\"\"\n",
    "        x_dados = self.sobre_o_df.data\n",
    "        y_objetivo = self.sobre_o_df.target\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "            x_dados,\n",
    "            y_objetivo,\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    def modelo_de_regreção_linear(self):\n",
    "        linear_regression = LinearRegression()\n",
    "\n",
    "        treinamento = (\n",
    "            linear_regression\n",
    "            .fit(X=self.x_train, y=self.y_train)\n",
    "        )\n",
    "\n",
    "        y_predict_linear = treinamento.predict(X=self.x_test)\n",
    "\n",
    "       # Avaliação do modelo:\n",
    "        mse = mean_squared_error(self.y_test, y_predict_linear)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        print(f'Previsão: \\n {y_predict_linear}')\n",
    "        print(f'MSE: {mse}')\n",
    "        print(f'RmSE: {rmse}')\n",
    "\n",
    "    def modelo_svr(self):\n",
    "        svr = SVR()\n",
    "\n",
    "        treinamento = (\n",
    "            svr\n",
    "            .fit(self.x_train, self.y_train)\n",
    "        )\n",
    "\n",
    "        y_svr = treinamento.predict(self.x_test)\n",
    "        \n",
    "        # Avaliação do modelo:\n",
    "        mse = mean_squared_error(self.y_test, y_svr)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        print(f'Previsão: \\n {y_svr}')\n",
    "        print(f'MSE: {mse}')\n",
    "        print(f'RmSE: {rmse}')\n",
    "\n",
    "    def modelo_xgb_regressor(self):\n",
    "        xgb_regressor = XGBRegressor()\n",
    "\n",
    "        treinamento = (\n",
    "            xgb_regressor\n",
    "            .fit(self.x_train, self.y_train)\n",
    "        )\n",
    "\n",
    "        y_xgb_regressor = treinamento.predict(self.x_test)\n",
    "        \n",
    "        # Avaliação do modelo:\n",
    "        mse = mean_squared_error(self.y_test, y_xgb_regressor)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        print(f'Previsão: \\n {y_xgb_regressor}')\n",
    "        print(f'MSE: {mse}')\n",
    "        print(f'RmSE: {rmse}')\n",
    "\n",
    "    def modelo_xgb_regressor_otimizado(self):\n",
    "        \n",
    "        parameters = {\n",
    "            \"max_depth\": [5, 6, 7],\n",
    "            \"learning_rate\": [0.1, 0.2,0.3],\n",
    "            \"objective\": ['reg:squarederror'],\n",
    "            \"booster\": ['gbtree'],\n",
    "            \"n_jobs\": [5],\n",
    "            \"gamma\": [0, 1],\n",
    "            \"min_child_weight\": [1,3],\n",
    "            \"max_delta_step\": [0,1],\n",
    "            \"subsample\": [0.5, 1]\n",
    "        }\n",
    "\n",
    "        xgb_regressor = XGBRegressor()\n",
    "\n",
    "        xgb = GridSearchCV(\n",
    "            estimator=xgb_regressor,\n",
    "            param_grid=parameters,\n",
    "            refit='neg_mean_squared_error',\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        treinamento = (\n",
    "            xgb\n",
    "            .fit(self.x_train, self.y_train)\n",
    "        )\n",
    "\n",
    "        keys = treinamento.get_params().keys()\n",
    "\n",
    "        y_xgb_regressor = treinamento.predict(self.x_test)\n",
    "        \n",
    "        # Avaliação do modelo:\n",
    "        mse = mean_squared_error(self.y_test, y_xgb_regressor)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        print(f'Parametros: {keys}')\n",
    "        print(f'Previsão: \\n {y_xgb_regressor}')\n",
    "        print(f'MSE: {mse}')\n",
    "        print(f'RmSE: {rmse}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_modeling = DataModeling()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniciando Código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_modeling.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "data_modeling.chaves_do_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_modeling.descrição_do_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "data_modeling.variavel_targat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modeling.separação_de_train_e_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsão: \n",
      " [28.99672362 36.02556534 14.81694405 25.03197915 18.76987992 23.25442929\n",
      " 17.66253818 14.34119    23.01320703 20.63245597 24.90850512 18.63883645\n",
      " -6.08842184 21.75834668 19.23922576 26.19319733 20.64773313  5.79472718\n",
      " 40.50033966 17.61289074 27.24909479 30.06625441 11.34179277 24.16077616\n",
      " 17.86058499 15.83609765 22.78148106 14.57704449 22.43626052 19.19631835\n",
      " 22.43383455 25.21979081 25.93909562 17.70162434 16.76911711 16.95125411\n",
      " 31.23340153 20.13246729 23.76579011 24.6322925  13.94204955 32.25576301\n",
      " 42.67251161 17.32745046 27.27618614 16.99310991 14.07009109 25.90341861\n",
      " 20.29485982 29.95339638 21.28860173 34.34451856 16.04739105 26.22562412\n",
      " 39.53939798 22.57950697 18.84531367 32.72531661 25.0673037  12.88628956\n",
      " 22.68221908 30.48287757 31.52626806 15.90148607 20.22094826 16.71089812\n",
      " 20.52384893 25.96356264 30.61607978 11.59783023 20.51232627 27.48111878\n",
      " 11.01962332 15.68096344 23.79316251  6.19929359 21.6039073  41.41377225\n",
      " 18.76548695  8.87931901 20.83076916 13.25620627 20.73963699  9.36482222\n",
      " 23.22444271 31.9155003  19.10228271 25.51579303 29.04256769 20.14358566\n",
      " 25.5859787   5.70159447 20.09474756 14.95069156 12.50395648 20.72635294\n",
      " 24.73957161 -0.164237   13.68486682 16.18359697 22.27621999 24.47902364]\n",
      "MSE: 24.29111947497343\n",
      "RmSE: 4.928602182665328\n"
     ]
    }
   ],
   "source": [
    "data_modeling.modelo_de_regreção_linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsão: \n",
      " [22.5061509  24.44637611 15.48342923 23.47861138 15.85575665 20.41359379\n",
      " 22.22729603 19.30750829 16.00684204 20.69013802 22.5948442  22.17932651\n",
      " 13.22283187 20.88634606 22.74343046 16.11962825 23.6578174  15.50113391\n",
      " 24.80649803 15.86119502 24.85903189 24.42774747 21.65632951 23.06890895\n",
      " 15.18170664 15.47518332 21.28809591 13.27760452 22.58811671 20.84375287\n",
      " 22.39598564 23.17949952 15.87553566 15.81646768 15.26751873 18.53736675\n",
      " 23.75510385 24.20893309 23.03137207 23.35824097 20.74014355 24.26097498\n",
      " 25.29050354 22.45914878 23.21111935 15.87406945 21.6649305  23.42123755\n",
      " 16.08170391 23.06164042 22.35542867 24.67123285 22.08392839 21.02076269\n",
      " 23.7698124  16.48115196 15.85681759 24.99519292 23.87040225 22.19275612\n",
      " 23.61440768 25.38561307 23.18766117 21.82639671 21.46613519 22.43757636\n",
      " 15.82206507 23.86467246 24.9310726  13.3354447  24.23171731 16.22743397\n",
      " 14.35580648 23.47121935 21.03977262 15.66672407 20.63701249 25.28324943\n",
      " 15.81293928 15.0221233  22.55700153 15.01570683 23.9667558  15.81774318\n",
      " 22.21717976 22.25414813 14.64314526 23.37372785 24.08220483 19.37699063\n",
      " 23.06367649 13.58347444 19.43566908 21.6322458  15.68851353 19.33195473\n",
      " 15.61256571 13.1513996  13.29101828 13.23316724 23.87811317 21.02772523]\n",
      "MSE: 52.8383657679667\n",
      "RmSE: 7.269000327965785\n"
     ]
    }
   ],
   "source": [
    "data_modeling.modelo_svr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsão: \n",
      " [23.25328   30.024755  15.632249  23.313478  17.775118  21.142563\n",
      " 20.19583   15.010124  21.23614   22.242369  20.457346  19.209145\n",
      "  8.551788  21.210636  20.696491  26.74365   18.824339  10.525872\n",
      " 45.68885   14.116162  26.618996  24.94542   13.3510275 20.87231\n",
      " 15.400073  15.636547  22.324673  12.777009  20.726126  22.56401\n",
      " 20.346395  22.303246  18.523277  21.764612  15.568828  15.683646\n",
      " 33.073547  19.115112  21.955132  22.399914  18.998787  31.328337\n",
      " 43.464993  18.20766   22.09233   14.353467  14.607512  22.716745\n",
      " 19.700527  27.072327  22.579268  35.133675  16.241447  25.214682\n",
      " 46.013332  21.89786   15.043295  32.93268   20.53731   16.568089\n",
      " 24.07178   34.34796   28.542194  16.977676  25.867334  15.649837\n",
      " 13.039615  23.00082   27.26897   15.414835  21.546648  31.72919\n",
      " 10.665012  20.770847  21.848396   6.475782  20.939093  46.59454\n",
      " 12.456056   8.739085  22.215406  13.390212  20.454681  10.45914\n",
      " 19.722834  27.327946  16.254663  23.860172  25.414312  17.06042\n",
      " 22.9362     8.106883  19.001764  18.869307  24.129864  19.66075\n",
      " 40.517284  13.981451  11.416717  15.428753  19.41982   24.281776 ]\n",
      "MSE: 6.560527271813469\n",
      "RmSE: 2.561352625433185\n"
     ]
    }
   ],
   "source": [
    "data_modeling.modelo_xgb_regressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Parametros: dict_keys(['cv', 'error_score', 'estimator__objective', 'estimator__base_score', 'estimator__booster', 'estimator__callbacks', 'estimator__colsample_bylevel', 'estimator__colsample_bynode', 'estimator__colsample_bytree', 'estimator__early_stopping_rounds', 'estimator__enable_categorical', 'estimator__eval_metric', 'estimator__feature_types', 'estimator__gamma', 'estimator__gpu_id', 'estimator__grow_policy', 'estimator__importance_type', 'estimator__interaction_constraints', 'estimator__learning_rate', 'estimator__max_bin', 'estimator__max_cat_threshold', 'estimator__max_cat_to_onehot', 'estimator__max_delta_step', 'estimator__max_depth', 'estimator__max_leaves', 'estimator__min_child_weight', 'estimator__missing', 'estimator__monotone_constraints', 'estimator__n_estimators', 'estimator__n_jobs', 'estimator__num_parallel_tree', 'estimator__predictor', 'estimator__random_state', 'estimator__reg_alpha', 'estimator__reg_lambda', 'estimator__sampling_method', 'estimator__scale_pos_weight', 'estimator__subsample', 'estimator__tree_method', 'estimator__validate_parameters', 'estimator__verbosity', 'estimator', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose'])\n",
      "Previsão: \n",
      " [23.768152  31.19189   16.761093  23.17162   17.716856  21.859089\n",
      " 19.134653  14.135722  21.355747  21.244808  20.512945  18.5687\n",
      "  7.895545  21.766296  19.894556  27.286322  19.855219   9.775071\n",
      " 47.104134  14.94226   25.203379  24.4944    13.590345  22.096859\n",
      " 15.463435  15.2345495 21.744184  13.067711  19.914896  21.482033\n",
      " 20.258598  22.99324   19.91889   20.73753   15.213837  16.06474\n",
      " 34.22609   19.076998  21.49956   23.521164  17.55079   30.56808\n",
      " 47.01719   18.34714   22.317083  14.4401455 15.142728  23.491951\n",
      " 18.68228   27.291855  21.245737  34.729874  15.092127  25.654999\n",
      " 44.971382  21.757538  15.2574    32.48651   22.340885  17.640186\n",
      " 24.442606  35.157986  28.700268  17.544847  25.977821  15.664102\n",
      " 13.331977  22.993616  28.47261   15.02147   20.737804  24.220512\n",
      " 10.499494  20.512321  21.898335   7.347535  21.151562  47.15974\n",
      " 12.425162  12.907234  22.033495  13.780466  18.511017   9.129063\n",
      " 20.42751   27.34589   15.905812  23.292997  24.021511  17.444641\n",
      " 22.45765    8.025354  17.616322  18.805393  24.965635  19.04447\n",
      " 35.93925   12.015111  12.016194  15.87417   19.820496  24.268528 ]\n",
      "MSE: 6.548084548074031\n",
      "RmSE: 2.5589225365520605\n"
     ]
    }
   ],
   "source": [
    "data_modeling.modelo_xgb_regressor_otimizado()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
